{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WJE6KwO718uC"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL_sea = 'https://www.amazon.co.uk/s?k=hard+drive&i=computers&rh=n%3A340831031%2Cp_89%3ASeagate&s=review-rank&dc&ds=v1%3A6SXEIuGkAa4qAp9wc0q0WWpwv7J6X5ClyHcnKyo15ds&crid=11I57DU1Q40BL&qid=1709561950&rnid=1632651031&sprefix=hard+driv%2Caps%2C205&ref=sr_st_review-rank'\n",
        "URL_west = 'https://www.amazon.co.uk/s?k=hard+drive&i=computers&rh=n%3A340831031%2Cp_89%3AWestern+Digital&s=review-rank&dc&crid=11I57DU1Q40BL&qid=1709562162&rnid=1632651031&sprefix=hard+driv%2Caps%2C205&ref=sr_nr_p_89_2&ds=v1%3A5dK5J9Pb%2FoivfgH9WeLD2TaqojHqEqgkjIRj1SupOnc'\n",
        "URL_sam = 'https://www.amazon.co.uk/s?k=hard+drive&i=computers&rh=n%3A340831031%2Cp_89%3ASamsung&s=review-rank&dc&crid=11I57DU1Q40BL&qid=1709562209&rnid=1632651031&sprefix=hard+driv%2Caps%2C205&ref=sr_nr_p_89_2&ds=v1%3ABwoBkg2JqfX1oDjRFD01KrMrPG%2B%2ByLRuvFvOIfW8awo'\n",
        "URL_san = 'https://www.amazon.co.uk/s?k=hard+drive&i=computers&rh=n%3A340831031%2Cp_89%3ASanDisk&s=review-rank&dc&crid=11I57DU1Q40BL&qid=1709562240&rnid=1632651031&sprefix=hard+driv%2Caps%2C205&ref=sr_nr_p_89_2&ds=v1%3ABfLP18lp%2F%2FUyQ61TyfXFBZ8MR1eKrMSiB8pQZTMy%2F0w'\n",
        "URL_cru = 'https://www.amazon.co.uk/s?k=hard+drive&i=computers&rh=n%3A340831031%2Cp_89%3ACrucial&dc&ds=v1%3A3tQlFt3qboE0VHotZfUKoiCdmhUJNOnNz9%2Bw1ZjEfek&crid=13VBQIRQGNOOE&qid=1709652649&rnid=1632651031&sprefix=hard+drive%2Ccomputers%2C224&ref=sr_nr_p_89_16'"
      ],
      "metadata": {
        "id": "_mFhTi8w1_S1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',\n",
        "            'Accept-Language':'en-US,en:q=0.5'})"
      ],
      "metadata": {
        "id": "CwRBQU_G2Cj5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "webpage_sea = requests.get(URL_sea,headers=HEADERS)\n",
        "webpage_west = requests.get(URL_west,headers=HEADERS)\n",
        "webpage_sam = requests.get(URL_sam,headers=HEADERS)\n",
        "webpage_san = requests.get(URL_san,headers=HEADERS)\n",
        "webpage_cru = requests.get(URL_cru,headers=HEADERS)"
      ],
      "metadata": {
        "id": "RU1jDynC2D6g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup_sea = BeautifulSoup(webpage_sea.content, 'html.parser')\n",
        "soup_west = BeautifulSoup(webpage_west.content, 'html.parser')\n",
        "soup_sam = BeautifulSoup(webpage_sam.content, 'html.parser')\n",
        "soup_san = BeautifulSoup(webpage_san.content, 'html.parser')\n",
        "soup_cru = BeautifulSoup(webpage_cru.content, 'html.parser')"
      ],
      "metadata": {
        "id": "Hqkl3y5i2E8W"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "links_sea = soup_sea.find_all('a',attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
        "links_west = soup_west.find_all('a',attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
        "links_sam = soup_sam.find_all('a',attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
        "links_san = soup_san.find_all('a',attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})\n",
        "links_cru = soup_cru.find_all('a',attrs={'class':'a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal'})"
      ],
      "metadata": {
        "id": "_mpWLO2G2GTX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link_set = [links_sea, links_west,links_sam,links_san,links_cru]\n",
        "df_name = ['df_sea','df_west','df_sam','df_san','df_cru']\n",
        "for i in link_set:\n",
        "  column_list = ['title','price','rating','rating_no','capacity','link']\n",
        "  df = pd.DataFrame(columns=column_list)\n",
        "  for link in i:\n",
        "    link = str(link.get('href'))\n",
        "    index = link.find('https://www.amazon.co.uk')\n",
        "    link = link[:index]\n",
        "    products = 'https://www.amazon.co.uk' + link\n",
        "    try:\n",
        "      new_page = requests.get(products,headers=HEADERS)\n",
        "      new_soup = BeautifulSoup(new_page.content, 'html.parser')\n",
        "      title = new_soup.find('span',attrs={'id':'productTitle'}).text.strip()\n",
        "      price = new_soup.find('span',attrs={'class':'a-price aok-align-center reinventPricePriceToPayMargin priceToPay'}).text.strip().replace('Â£','')\n",
        "      rating = new_soup.find('span',attrs={'class':'a-icon-alt'}).text.strip()\n",
        "      rating_no = new_soup.find('span',attrs={'id':'acrCustomerReviewText'}).text.strip()\n",
        "      index = title.find('TB')\n",
        "      cap = title[index-2:index+2].replace(' ','').replace('.','').replace(',','')\n",
        "      if index == -1:\n",
        "        index = title.find('GB')\n",
        "        cap = title[index-4:index+2].replace(' ','').replace('.','').replace(',','')\n",
        "    except Exception:\n",
        "      pass\n",
        "    finally:\n",
        "      entry = [title,price,rating,rating_no,cap,products]\n",
        "      df.loc[len(df)] = entry\n",
        "  df = df.drop_duplicates(subset=['price','rating','rating_no'])\n",
        "  print(df)\n",
        "  num = link_set.index(i)\n",
        "  name = df_name[num]\n",
        "  df.to_csv(f'{name}.csv',index = False)"
      ],
      "metadata": {
        "id": "V8JF8GCdRlVG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}